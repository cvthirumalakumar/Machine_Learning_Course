{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0cc64187-6b01-47a9-95fc-8d9df49ddced",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ef3af9d-1929-462a-b17f-54cedbde5c66",
   "metadata": {},
   "source": [
    "# Part 1 : Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "71ab69cb-be4e-46e2-a03a-72632f008f4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MFCCs_ 1</th>\n",
       "      <th>MFCCs_ 2</th>\n",
       "      <th>MFCCs_ 3</th>\n",
       "      <th>MFCCs_ 4</th>\n",
       "      <th>MFCCs_ 5</th>\n",
       "      <th>MFCCs_ 6</th>\n",
       "      <th>MFCCs_ 7</th>\n",
       "      <th>MFCCs_ 8</th>\n",
       "      <th>MFCCs_9</th>\n",
       "      <th>MFCCs_10</th>\n",
       "      <th>...</th>\n",
       "      <th>MFCCs_15</th>\n",
       "      <th>MFCCs_16</th>\n",
       "      <th>MFCCs_17</th>\n",
       "      <th>MFCCs_18</th>\n",
       "      <th>MFCCs_19</th>\n",
       "      <th>MFCCs_20</th>\n",
       "      <th>MFCCs_21</th>\n",
       "      <th>Family</th>\n",
       "      <th>Genus</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.152936</td>\n",
       "      <td>-0.105586</td>\n",
       "      <td>0.200722</td>\n",
       "      <td>0.317201</td>\n",
       "      <td>0.260764</td>\n",
       "      <td>0.100945</td>\n",
       "      <td>-0.150063</td>\n",
       "      <td>-0.171128</td>\n",
       "      <td>0.124676</td>\n",
       "      <td>0.188654</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.024017</td>\n",
       "      <td>-0.108351</td>\n",
       "      <td>-0.077623</td>\n",
       "      <td>-0.009568</td>\n",
       "      <td>0.057684</td>\n",
       "      <td>0.118680</td>\n",
       "      <td>0.014038</td>\n",
       "      <td>Leptodactylidae</td>\n",
       "      <td>Adenomera</td>\n",
       "      <td>AdenomeraAndre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.171534</td>\n",
       "      <td>-0.098975</td>\n",
       "      <td>0.268425</td>\n",
       "      <td>0.338672</td>\n",
       "      <td>0.268353</td>\n",
       "      <td>0.060835</td>\n",
       "      <td>-0.222475</td>\n",
       "      <td>-0.207693</td>\n",
       "      <td>0.170883</td>\n",
       "      <td>0.270958</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012022</td>\n",
       "      <td>-0.090974</td>\n",
       "      <td>-0.056510</td>\n",
       "      <td>-0.035303</td>\n",
       "      <td>0.020140</td>\n",
       "      <td>0.082263</td>\n",
       "      <td>0.029056</td>\n",
       "      <td>Leptodactylidae</td>\n",
       "      <td>Adenomera</td>\n",
       "      <td>AdenomeraAndre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.152317</td>\n",
       "      <td>-0.082973</td>\n",
       "      <td>0.287128</td>\n",
       "      <td>0.276014</td>\n",
       "      <td>0.189867</td>\n",
       "      <td>0.008714</td>\n",
       "      <td>-0.242234</td>\n",
       "      <td>-0.219153</td>\n",
       "      <td>0.232538</td>\n",
       "      <td>0.266064</td>\n",
       "      <td>...</td>\n",
       "      <td>0.083536</td>\n",
       "      <td>-0.050691</td>\n",
       "      <td>-0.023590</td>\n",
       "      <td>-0.066722</td>\n",
       "      <td>-0.025083</td>\n",
       "      <td>0.099108</td>\n",
       "      <td>0.077162</td>\n",
       "      <td>Leptodactylidae</td>\n",
       "      <td>Adenomera</td>\n",
       "      <td>AdenomeraAndre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.224392</td>\n",
       "      <td>0.118985</td>\n",
       "      <td>0.329432</td>\n",
       "      <td>0.372088</td>\n",
       "      <td>0.361005</td>\n",
       "      <td>0.015501</td>\n",
       "      <td>-0.194347</td>\n",
       "      <td>-0.098181</td>\n",
       "      <td>0.270375</td>\n",
       "      <td>0.267279</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.050224</td>\n",
       "      <td>-0.136009</td>\n",
       "      <td>-0.177037</td>\n",
       "      <td>-0.130498</td>\n",
       "      <td>-0.054766</td>\n",
       "      <td>-0.018691</td>\n",
       "      <td>0.023954</td>\n",
       "      <td>Leptodactylidae</td>\n",
       "      <td>Adenomera</td>\n",
       "      <td>AdenomeraAndre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.087817</td>\n",
       "      <td>-0.068345</td>\n",
       "      <td>0.306967</td>\n",
       "      <td>0.330923</td>\n",
       "      <td>0.249144</td>\n",
       "      <td>0.006884</td>\n",
       "      <td>-0.265423</td>\n",
       "      <td>-0.172700</td>\n",
       "      <td>0.266434</td>\n",
       "      <td>0.332695</td>\n",
       "      <td>...</td>\n",
       "      <td>0.062837</td>\n",
       "      <td>-0.048885</td>\n",
       "      <td>-0.053074</td>\n",
       "      <td>-0.088550</td>\n",
       "      <td>-0.031346</td>\n",
       "      <td>0.108610</td>\n",
       "      <td>0.079244</td>\n",
       "      <td>Leptodactylidae</td>\n",
       "      <td>Adenomera</td>\n",
       "      <td>AdenomeraAndre</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   MFCCs_ 1  MFCCs_ 2  MFCCs_ 3  MFCCs_ 4  MFCCs_ 5  MFCCs_ 6  MFCCs_ 7  \\\n",
       "0  0.152936 -0.105586  0.200722  0.317201  0.260764  0.100945 -0.150063   \n",
       "1  0.171534 -0.098975  0.268425  0.338672  0.268353  0.060835 -0.222475   \n",
       "2  0.152317 -0.082973  0.287128  0.276014  0.189867  0.008714 -0.242234   \n",
       "3  0.224392  0.118985  0.329432  0.372088  0.361005  0.015501 -0.194347   \n",
       "4  0.087817 -0.068345  0.306967  0.330923  0.249144  0.006884 -0.265423   \n",
       "\n",
       "   MFCCs_ 8   MFCCs_9  MFCCs_10  ...  MFCCs_15  MFCCs_16  MFCCs_17  MFCCs_18  \\\n",
       "0 -0.171128  0.124676  0.188654  ... -0.024017 -0.108351 -0.077623 -0.009568   \n",
       "1 -0.207693  0.170883  0.270958  ...  0.012022 -0.090974 -0.056510 -0.035303   \n",
       "2 -0.219153  0.232538  0.266064  ...  0.083536 -0.050691 -0.023590 -0.066722   \n",
       "3 -0.098181  0.270375  0.267279  ... -0.050224 -0.136009 -0.177037 -0.130498   \n",
       "4 -0.172700  0.266434  0.332695  ...  0.062837 -0.048885 -0.053074 -0.088550   \n",
       "\n",
       "   MFCCs_19  MFCCs_20  MFCCs_21           Family      Genus         Species  \n",
       "0  0.057684  0.118680  0.014038  Leptodactylidae  Adenomera  AdenomeraAndre  \n",
       "1  0.020140  0.082263  0.029056  Leptodactylidae  Adenomera  AdenomeraAndre  \n",
       "2 -0.025083  0.099108  0.077162  Leptodactylidae  Adenomera  AdenomeraAndre  \n",
       "3 -0.054766 -0.018691  0.023954  Leptodactylidae  Adenomera  AdenomeraAndre  \n",
       "4 -0.031346  0.108610  0.079244  Leptodactylidae  Adenomera  AdenomeraAndre  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"Q1Data.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c891bce5-c7d2-4e3b-acab-a8e77c62ef0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "data['Labels_numeric'] = label_encoder.fit_transform(data['Genus'])\n",
    "classes_mapping = dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)))\n",
    "x,y = data.iloc[:,:6].to_numpy(),data['Labels_numeric'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "17f87933-7275-4440-86a7-49974480d385",
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy(probs):\n",
    "    return -np.sum(probs * np.log2(probs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f7cdb048-7836-4d3d-929b-c4b8647dd435",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9182958340544896"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entropy([3/9,6/9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "85dd0f2e-3551-4140-9caa-57718b55df33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "depth 0\n",
      "finding split\n",
      "feature 0\n",
      "threshold 0 left {0, 1} right {0, 1}\n",
      "infogain 1.0\n",
      "threshold 1 left {0, 1} right set()\n",
      "infogain 1.0\n",
      "feature 1\n",
      "threshold 0 left {0, 1} right {0, 1}\n",
      "infogain 1.0\n",
      "threshold 1 left {0, 1} right set()\n",
      "infogain 1.0\n",
      "0 0 1.0\n",
      "depth 1\n",
      "finding split\n",
      "feature 0\n",
      "threshold 0 left {0, 1} right set()\n",
      "infogain 1.0\n",
      "feature 1\n",
      "threshold 0 left {0} right {1}\n",
      "infogain -0.0\n",
      "threshold 1 left {0, 1} right set()\n",
      "infogain 1.0\n",
      "1 0 -0.0\n",
      "depth 2\n",
      "2 True False\n",
      "depth 2\n",
      "2 True False\n",
      "depth 1\n",
      "finding split\n",
      "feature 0\n",
      "threshold 1 left {0, 1} right set()\n",
      "infogain 1.0\n",
      "feature 1\n",
      "threshold 0 left {1} right {0}\n",
      "infogain -0.0\n",
      "threshold 1 left {0, 1} right set()\n",
      "infogain 1.0\n",
      "1 0 -0.0\n",
      "depth 2\n",
      "2 True False\n",
      "depth 2\n",
      "2 True False\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "class DecisionTree:\n",
    "    def __init__(self, max_depth=None):\n",
    "        self.max_depth = max_depth\n",
    "        self.tree_ = None\n",
    "    def fit(self, X, y, depth=0):\n",
    "        # Check if all labels are the same or if max depth is reached\n",
    "        print('depth',depth)\n",
    "        if len(set(y)) == 1 or depth == self.max_depth:\n",
    "            print(depth,len(set(y)) == 1,depth == self.max_depth)\n",
    "            return {'class': np.bincount(y).argmax()}\n",
    "\n",
    "        # Find the best feature and threshold to split on\n",
    "        best_feature, threshold = self.find_best_split(X, y)\n",
    "\n",
    "        # if best_feature is None:\n",
    "        #     print(depth)\n",
    "        #     return {'class': np.bincount(y).argmax()}\n",
    "\n",
    "        # Split the dataset based on the best feature and threshold\n",
    "        left_indices = X[:, best_feature] <= threshold\n",
    "        right_indices = ~left_indices\n",
    "\n",
    "        # Check if any split is empty\n",
    "        if not np.any(left_indices) or not np.any(right_indices):\n",
    "            return {'class': np.bincount(y).argmax()}\n",
    "\n",
    "        # Store split information in the current node\n",
    "        node = {'feature': best_feature, 'threshold': threshold}\n",
    "\n",
    "        # Recursively build subtrees\n",
    "        node['left'] = self.fit(X[left_indices], y[left_indices], depth + 1)\n",
    "        node['right'] = self.fit(X[right_indices], y[right_indices], depth + 1)\n",
    "\n",
    "        self.tree_ = node\n",
    "        return node\n",
    "\n",
    "    def find_best_split(self, X, y):\n",
    "        num_features = X.shape[1]\n",
    "        best_feature, best_threshold, best_score = None, None, 100\n",
    "        print(\"finding split\")\n",
    "        for feature in range(num_features):\n",
    "            thresholds = np.unique(X[:, feature])\n",
    "            print('feature',feature)\n",
    "\n",
    "            for threshold in thresholds:\n",
    "                left_indices = X[:, feature] <= threshold\n",
    "                right_indices = ~left_indices\n",
    "                print('threshold',threshold,'left',set(y[left_indices]),'right',set(y[right_indices]))\n",
    "\n",
    "                # if len(set(y[left_indices])) > 1 and len(set(y[right_indices])) > 1:\n",
    "                info_gain = self.calculate_information_gain(y, y[left_indices], y[right_indices])\n",
    "                print(\"infogain\",info_gain)\n",
    "                if info_gain < best_score:\n",
    "                    best_score = info_gain\n",
    "                    best_feature = feature\n",
    "                    best_threshold = threshold\n",
    "        print(best_feature, best_threshold,best_score)\n",
    "        return best_feature, best_threshold\n",
    "\n",
    "    def calculate_information_gain(self, parent, left_child, right_child):\n",
    "        p = len(parent)\n",
    "        pl = len(left_child)\n",
    "        pr = len(right_child)\n",
    "\n",
    "        entropy_children = (pl / p) * self.calculate_entropy(left_child) + (pr / p) * self.calculate_entropy(right_child)\n",
    "\n",
    "        return entropy_children\n",
    "\n",
    "    def calculate_entropy(self, labels):\n",
    "        _, counts = np.unique(labels, return_counts=True)\n",
    "        probabilities = counts / len(labels)\n",
    "        entropy = -np.sum(probabilities * np.log2(probabilities))\n",
    "        return entropy\n",
    "\n",
    "    def predict_instance(self, x, node):\n",
    "        if 'class' in node:\n",
    "            return node['class']\n",
    "\n",
    "        if x[node['feature']] <= node['threshold']:\n",
    "            return self.predict_instance(x, node['left'])\n",
    "        else:\n",
    "            return self.predict_instance(x, node['right'])\n",
    "\n",
    "    def predict(self, X):\n",
    "        return [self.predict_instance(x, self.tree_) for x in X]\n",
    "\n",
    "# Example usage:\n",
    "# Assuming X_train and y_train are your training data and labels\n",
    "X_train = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "y_train = np.array([0, 1, 1, 0])\n",
    "X_train_dummy_large = np.random.randint(0, 2, size=(100, 2))\n",
    "\n",
    "# Binary target variable\n",
    "# Assuming a simple XOR pattern\n",
    "y_train_dummy_large = np.logical_xor(X_train_dummy_large[:, 0], X_train_dummy_large[:, 1]).astype(int)\n",
    "\n",
    "# Create and train the decision tree\n",
    "tree = DecisionTree(max_depth=3)\n",
    "# a = tree.fit(X_train_dummy_large, y_train_dummy_large)\n",
    "\n",
    "tree.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "X_test = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "predictions = tree.predict(X_test)\n",
    "\n",
    "# print(predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "906ce13f-7b31-48a7-bc16-97e6ee1563fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'feature': 0,\n",
       " 'threshold': 0,\n",
       " 'left': {'feature': 1,\n",
       "  'threshold': 0,\n",
       "  'left': {'class': 0},\n",
       "  'right': {'class': 1}},\n",
       " 'right': {'feature': 1,\n",
       "  'threshold': 0,\n",
       "  'left': {'class': 1},\n",
       "  'right': {'class': 0}}}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree.tree_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "0e2fa306-2f0c-4209-965c-73af7372ecda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.DecisionTree at 0x7f2425421b40>"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "40bdfcb9-47bb-419e-8d1b-5c490620b401",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1,\n",
       "       1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0,\n",
       "       1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0,\n",
       "       1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_dummy_large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "f938a9b2-6975-4a88-bfcb-83f82976e5ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.array(predictions)==y_train_dummy_large)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc45d939-3104-4876-a1d3-5b1205e3ba74",
   "metadata": {},
   "source": [
    "# latest code from chatgpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "d040280d-515e-4901-9142-4190fef66190",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class DecisionTree:\n",
    "    def __init__(self, max_depth=None):\n",
    "        self.max_depth = max_depth\n",
    "        self.tree_ = None\n",
    "\n",
    "    def fit(self, X, y, depth=0):\n",
    "        # Check if all labels are the same or if max depth is reached\n",
    "        if len(set(y)) == 1 or depth == self.max_depth:\n",
    "            return {'class': np.bincount(y).argmax()}\n",
    "\n",
    "        # Find the best feature and threshold to split on\n",
    "        best_feature, threshold = self.find_best_split(X, y)\n",
    "\n",
    "        if best_feature is None:\n",
    "            return {'class': np.bincount(y).argmax()}\n",
    "\n",
    "        # Split the dataset based on the best feature and threshold\n",
    "        left_indices = X[:, best_feature] <= threshold\n",
    "        right_indices = ~left_indices\n",
    "\n",
    "        # Check if any split is empty\n",
    "        if not np.any(left_indices) or not np.any(right_indices):\n",
    "            return {'class': np.bincount(y).argmax()}\n",
    "\n",
    "        # Store split information in the current node\n",
    "        node = {'feature': best_feature, 'threshold': threshold}\n",
    "\n",
    "        # Recursively build subtrees\n",
    "        node['left'] = self.fit(X[left_indices], y[left_indices], depth + 1)\n",
    "        node['right'] = self.fit(X[right_indices], y[right_indices], depth + 1)\n",
    "\n",
    "        self.tree_ = node\n",
    "        return node\n",
    "\n",
    "    def find_best_split(self, X, y):\n",
    "        num_features = X.shape[1]\n",
    "        best_feature, best_threshold, best_score = None, None, -10\n",
    "\n",
    "        for feature in range(num_features):\n",
    "            thresholds = np.unique(X[:, feature])\n",
    "\n",
    "            for threshold in thresholds:\n",
    "                left_indices = X[:, feature] <= threshold\n",
    "                right_indices = ~left_indices\n",
    "\n",
    "                info_gain = self.calculate_information_gain(y, y[left_indices], y[right_indices])\n",
    "                if info_gain > best_score:\n",
    "                    best_score = info_gain\n",
    "                    best_feature = feature\n",
    "                    best_threshold = threshold\n",
    "\n",
    "        return best_feature, best_threshold\n",
    "\n",
    "    def calculate_information_gain(self, parent, left_child, right_child):\n",
    "        p = len(parent)\n",
    "        pl = len(left_child)\n",
    "        pr = len(right_child)\n",
    "\n",
    "        entropy_parent = self.calculate_entropy(parent)\n",
    "        entropy_children = (pl / p) * self.calculate_entropy(left_child) + (pr / p) * self.calculate_entropy(right_child)\n",
    "\n",
    "        return entropy_parent - entropy_children\n",
    "\n",
    "    def calculate_entropy(self, labels):\n",
    "        _, counts = np.unique(labels, return_counts=True)\n",
    "        probabilities = counts / len(labels)\n",
    "        entropy = -np.sum(probabilities * np.log2(probabilities + 1e-10))\n",
    "        return entropy\n",
    "\n",
    "    def predict_instance(self, x, node):\n",
    "        if 'class' in node:\n",
    "            return node['class']\n",
    "\n",
    "        if x[node['feature']] <= node['threshold']:\n",
    "            return self.predict_instance(x, node['left'])\n",
    "        else:\n",
    "            return self.predict_instance(x, node['right'])\n",
    "\n",
    "    def predict(self, X):\n",
    "        return [self.predict_instance(x, self.tree_) for x in X]\n",
    "\n",
    "# Example usage:\n",
    "# Assuming X_train and y_train are your training data and labels\n",
    "X_train = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "y_train = np.array([0, 1, 1, 0])\n",
    "\n",
    "# Create and train the decision tree\n",
    "tree = DecisionTree(max_depth=2)\n",
    "tree.fit(X_train_dummy_large, y_train_dummy_large)\n",
    "\n",
    "# Make predictions\n",
    "X_test = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "predictions = tree.predict(X_train_dummy_large)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "648d573f-b5cb-48e2-a8b6-3222634c2d2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree.max_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "03292d4e-7b3f-4ef3-8d52-f3764d19d448",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'feature': 1,\n",
       " 'threshold': 0,\n",
       " 'left': {'feature': 0,\n",
       "  'threshold': 0,\n",
       "  'left': {'class': 0},\n",
       "  'right': {'class': 1}},\n",
       " 'right': {'feature': 0,\n",
       "  'threshold': 0,\n",
       "  'left': {'class': 1},\n",
       "  'right': {'class': 0}}}"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree.tree_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "6405fb67-0d8a-4301-8edd-2e3faa294481",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'feature': 0,\n",
       " 'threshold': 0,\n",
       " 'left': {'feature': 1,\n",
       "  'threshold': 0,\n",
       "  'left': {'class': 0},\n",
       "  'right': {'class': 1}},\n",
       " 'right': {'feature': 1,\n",
       "  'threshold': 0,\n",
       "  'left': {'class': 1},\n",
       "  'right': {'class': 0}}}"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "92894efb-13f8-4602-b6d1-12f530d3923d",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = tree.predict(X_train_dummy_large,a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "774a5365-3d68-4a0d-bb47-13d83beb7068",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.array(predictions)==y_train_dummy_large)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "d3b4276e-6418-445a-8472-1c429fdbe4e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True])"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(predictions)==y_train_dummy_large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "ed8922e8-4496-4b54-a203-5a8d0c0b626a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1,\n",
       "       0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1,\n",
       "       1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1,\n",
       "       0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1,\n",
       "       1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0])"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_dummy_large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "5cad05ae-ca7b-46cd-a3c1-872cca496adb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(np.array(predictions) == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "45df5a99-ee91-41fe-abfe-d1602f22ee90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.bincount(np.array(predictions)).argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f5650d-ea2b-4c12-9171-a075eaa82549",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
